# **When Technology Truly "Disappears": Reflections on Reading Weiser's *The Computer for the 21st Century***

> **Abstract**  
> Revisiting Mark Weiser's 1991 vision in 2025 feels like looking into a mirror of our current reality. In this reflection, I connect his concept of "invisible computing" to my own observations—from the simplicity of a self-heating vest to the language barriers I faced in Germany. By contrasting Weiser's ideals with today's VR trends and "standalone" software mindsets, I realize that our technological path has deviated. My ultimate concern lies with emerging AI agents: when technology finally "disappears" and acts on our behalf, are we gaining convenience, or are we quietly surrendering our agency to algorithmic manipulation?


Mark Weiser's first sentence, written in 1991, struck a chord with me immediately:

**"The most profound technologies are those that disappear. They weave themselves into the fabric of everyday life until they are indistinguishable from it."**

## **Thoughts Triggered by a Heated Vest**

Reading this, the first thing that popped into my head wasn't some high-tech chip, but a **self-heating vest** a classmate bought back in high school. The principle was simple: a power bank in the pocket connected to graphene material inside the lining, which generated uniform heat when powered on.

This item, which I had never previously associated with "electronic devices," actually fits Weiser's description. Compared to a bulky down jacket, that vest was thin and warm. To the eye, it was indistinguishable from ordinary clothing, yet it solved the problem of "being cold" in a more natural and invisible way.

If computers or AI could be like that heating fabric—woven into the "cloth" of our lives, rather than being a cold "box" we have to deliberately operate—how wonderful would that be?

## **Invisible Like "Literacy"**

Weiser uses "Literacy" as a brilliant metaphor. The reason writing has "disappeared" is that we are so good at reading. When we look at a street sign, we absorb the information directly without realizing we are performing the "operation of reading."

This led me to a reflection: **Technology can only truly disappear when users can use it without learning.**

Although everyone has a smartphone today, and it even carries our emotional needs, has it really "disappeared"? No. Whether it's the elderly feeling lost with smartphones, or us awkwardly searching for tutorials in settings menus, it shows that a huge cognitive threshold still exists.

Even more interesting was my thought about my experience on the streets of Germany. Because of the language barrier, the information on those street signs didn't "automatically present itself" to me; I had to pull out a translation app to decode it. Does this mean that Weiser's ideal Ubiquitous Computing also implies breaking down language barriers?

## **The VR "Trap" vs. "Embodied Virtuality"**

The article mentions that Virtual Reality (VR) is the opposite of Ubiquitous Computing. At first, I didn't quite understand—isn't VR also an immersive intelligent environment?

After reading and thinking, I understood the key difference:

* **The logic of VR is "Escape"**—it creates a more stimulating virtual world, making the computer the center of attention (**Focus**). This is exactly what countless Apps are doing today: fighting for user attention, using algorithms to immerse you, making you forget reality.  
* **The logic of Weiser is "Enhancement"**—he calls it "**Embodied Virtuality**," bringing code out of its electronic shell and into the real world. This, conversely, can reduce people's investment in and dependence on the virtual world, making life feel more comfortable and refreshing.

This also explains why I felt exhausted after using a headset for a short time in a VR experience center. They were forcibly hijacking my senses. What Weiser wants is: **Technology is present, but I don't care about it; I don't need to know where it is to complete my task.**

Speaking of this, I can't help but think of current smart home devices from Xiaomi, Huawei, etc. Their concept seems similar to the "Internet of Everything," but often we still need to operate them via a smartphone App (a "remote control") or shout a wake word. This is still "humans adapting to machines." The smart home Weiser envisioned should be the environment actively sensing me rather than waiting for my commands.

## **Re-examining the Three Scales: Tabs, Pads, Boards**

Weiser envisioned three types of devices. I tried to map modern products onto them, only to find my initial understanding was completely wrong.

### **1\. Tabs are NOT AirTags**

Seeing "inch-sized" Tabs, my first reaction was Apple's AirTag. But after a deeper comparison, I realized AirTag is just an isolated, "mute" beacon that only tells you "I am here."

Weiser's Tabs are active micro-computers. They not only know where they are but also serve as interactive interfaces, or even bring dead objects to life—like making a file cabinet open automatically. We have not yet built that "environmental system" where objects communicate and collaborate with each other.

### **2\. Pads are NOT iPads**

Weiser criticized computers that need to be carried around as a "failure." This sounded harsh, given that I carry my Pad everywhere and use it for notes instead of paper. But thinking carefully, true portability isn't "me carrying the device," but "the device being everywhere in the environment."

Future Pads should be as cheap as paper; they are part of the environment, strictly "identity-less" intelligence that I can pick up to use and put down to leave.

### **3\. Boards are NOT Screen Sharing**

This was my biggest point of confusion. Isn't today's Zoom screen sharing essentially "Boards"?

Through deeper thought, I finally understood: Zoom is "me broadcasting my screen to you," which is still device-centric. Weiser's Liveboard is space-centric—it is a physically existing public object that everyone collaborates around, rather than everyone staring at their own small screens. Current collaboration software shares a "file" in the cloud; Weiser wanted us to share a "physical space," or true distributed devices within the same room.

## **The Real Pain Point: Standalone vs. Distributed Mindset**

The further I read, the more I felt that the lag in software architecture is the real bottleneck. Our software today is still stuck in a "**Standalone Mindset**."

Take a common example: If I log into WeChat on a new device and want to view past chat history, I have to wait for it to download gigabytes of data from the server to the local storage, which takes minutes.

This is the typical "Client \+ Server" model. Essentially, it is network transmission \+ local computing. The data is fixed, and the application is isolated.

I once wondered: "Doesn't all software connect to the internet now? Isn't that network computing?" Actually, it's not. It's just local computing with a network pipe.

I later realized: **Being connected to the internet does not equal being Distributed.** The Distributed Computing Weiser spoke of treats "**Location**" as core information.

* **Current Logic:** I open a document anywhere, and I see the exact same thing (because it's pulled from the cloud).  
* **Weiser's Logic:** When I walk into a room, dozens or hundreds of devices (Tabs, Pads) in the room identify that "**I am here**." Consequently, the screen in the study automatically displays my documents, and the alarm clock in the bedroom detects me stirring and asks, "Coffee?"

In this scenario, devices are **dynamically fluid**. I enter a room, and the devices there automatically form a system to serve me; I leave, and they disband. It's not like plugging in a USB drive where I have to manually configure everything. This requires a brand-new operating system capable of adapting to the environment like a biological organism, rather than the fixed-hardware OS we have today.

## **A Final Warning**

Although Weiser depicts a beautiful future—technology serving us like a butler from the old days—his warning at the end sent a chill down my spine:

**“Hundreds of computers in every room, all capable of sensing people near them and linked by high-speed networks, have the potential to make totalitarianism up to now seem like sheerest anarchy”**

However, in 2025, we face a threat even more subtle than the loss of **Privacy**: it is **Manipulation**.

This concern has become more concrete in this AI era. I thought of ByteDance's "Doubao Phone" (and similar AI Agent concepts). This phone isn't satisfied with being a voice assistant; it lets AI truly take over the phone—you give a command, and the AI orders food, shops online, or even grinds through daily quests in games for you.

But this sparked huge controversy and was even restricted by giants like WeChat. On the surface, it's about security, but the deeper logic is worth pondering:

When AI operates on your behalf, the commercial model collapses.

Current e-commerce and content platforms rely on "human browsing"—merchants pay the platform (ads, ranking bids) for traffic. If AI buys things for you, it skips those flashy ad interfaces and places the order directly.

Even scarier is the issue of "**Algorithmic Neutrality**": If I ask AI to recommend headphones, is the one it recommends truly the best, or is it because the backend weights were tweaked? If profit is mixed into the recommendation process, AI is no longer objective.

When technology "disappears" into the background like text, and when AI makes decisions for us like a butler, we not only lose the perception of "being watched," but we might also lose the right to choose. This may be the price we must stay awake to as we pursue the path of "invisible technology."

